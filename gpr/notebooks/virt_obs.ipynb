{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403d05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "others_path = os.path.join(current_dir, '..', 'gpr')\n",
    "\n",
    "others_path = os.path.abspath(others_path)\n",
    "if others_path not in sys.path:\n",
    "    sys.path.append(others_path)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections.abc import Callable\n",
    "import cvxpy as cp\n",
    "\n",
    "import eos\n",
    "from kernels import Kernel\n",
    "import gaussianprocess\n",
    "import finitedimensionalgp\n",
    "import sampling as sam\n",
    "import prepare_ceft as pc\n",
    "import prepare_pqcd as pp\n",
    "import anal_helpers as anal\n",
    "from pqcd.pQCD import pQCD\n",
    "from constants import get_phi, ns\n",
    "import virtobs as vo\n",
    "\n",
    "from pathlib import Path\n",
    "notebook_dir = Path.cwd()\n",
    "\n",
    "from scipy.linalg import cholesky, solve_triangular, cho_solve\n",
    "from scipy.stats import norm\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9a939",
   "metadata": {},
   "source": [
    "# the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37d04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 25\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_pqcd_grid = np.linspace(25, 40, grid_size) * 0.16   # fm⁻³\n",
    "X_grid = np.geomspace(0.5, 2.0, 40)              # or use np.geomspace\n",
    "\n",
    "cs2_family = []\n",
    "for X in X_grid:\n",
    "    n_raw, cs2_raw = pp.get_pqcd(X)\n",
    "    n_raw = n_raw * 0.16                        # convert to fm⁻³\n",
    "    cs2_interp = np.interp(n_pqcd_grid, n_raw, cs2_raw)\n",
    "    cs2_family.append(cs2_interp)\n",
    "\n",
    "cs2_family = np.array(cs2_family)               # shape: (n_X, n_n)\n",
    "cs2_min = cs2_family.min(axis=0)\n",
    "cs2_max = cs2_family.max(axis=0)\n",
    "\n",
    "mu_pqcd_grid = np.linspace(2.2,3,grid_size)*1000\n",
    "\n",
    "mu_family = []\n",
    "for X in X_grid:\n",
    "    n_raw, cs2_raw = pp.get_pqcd(X, size=grid_size)\n",
    "    n_raw = n_raw * 0.16                        # convert to fm⁻³\n",
    "    mu_interp = np.interp(n_pqcd_grid, n_raw, mu_pqcd_grid)\n",
    "    mu_family.append(mu_interp)\n",
    "\n",
    "mu_family = np.array(mu_family)               # shape: (n_X, n_n)\n",
    "mu_min = mu_family.min(axis=0)\n",
    "mu_max = mu_family.max(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f7e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ceft, cs2_ceft, cs2_l, cs2_u = anal.get_ceft_cs2()\n",
    "cs2_ceft_sigma = pc.CI_to_sigma(cs2_u-cs2_l)\n",
    "cs2_hat, X_hat, sigma_hat, l_hat, alpha_hat = sam.get_hype_samples('SE')\n",
    "\n",
    "cs2_ceft = cs2_ceft \n",
    "\n",
    "n = n_ceft*ns\n",
    "cs2 = cs2_ceft\n",
    "cs2_sigma = cs2_ceft_sigma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade0a92",
   "metadata": {},
   "source": [
    "# set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a3c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    #return np.maximum(x, 0) + np.log1p(np.exp(-np.abs(x)))\n",
    "    return np.log1p(np.exp(x))\n",
    "\n",
    "def log_likelihood_approx(zeta, A, b, eta):\n",
    "    \"\"\"\n",
    "    Approximate log likelihood for linear constraints A zeta + b >= 0\n",
    "    using a scaled sigmoid function.\n",
    "\n",
    "    zeta: (d,) current sample\n",
    "    A: (m, d) constraint matrix\n",
    "    b: (m,) constraint offset\n",
    "    eta: approximation strength\n",
    "\n",
    "    Returns: scalar log likelihood\n",
    "    \"\"\"\n",
    "    logits = A @ zeta + b\n",
    "    return -np.sum(softplus(-eta * logits))\n",
    "\n",
    "def sample_prior(cov):\n",
    "    \"\"\"\n",
    "    Sample from N(0, cov)\n",
    "    \"\"\"\n",
    "    return np.random.multivariate_normal(mean=np.zeros(cov.shape[0]), cov=cov)\n",
    "\n",
    "def project_onto_constraints(A, b, z):\n",
    "    \"\"\"\n",
    "    Project vector z onto the feasible set defined by A x + b >= 0\n",
    "    using CVXPY with CLARABEL solver.\n",
    "    Solves: min_x 0.5 * ||x - z||² subject to A x + b >= 0\n",
    "    \"\"\"\n",
    "    d = z.shape[0]\n",
    "    x = cp.Variable(d)\n",
    "\n",
    "    objective = cp.Minimize(0.5 * cp.sum_squares(x - z))\n",
    "    constraints = [A @ x + b >= 0]\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    \n",
    "    problem.solve(solver=cp.CLARABEL, verbose=False)\n",
    "\n",
    "    if problem.status not in [\"optimal\", \"optimal_inaccurate\"]:\n",
    "        raise RuntimeError(f\"Projection failed: {problem.status}\")\n",
    "    \n",
    "    return x.value\n",
    "\n",
    "def elliptical_slice_sampling(f, cov, A, b, eta, log_likelihood_fn, max_attempts=100000):\n",
    "    nu = sample_prior(cov)\n",
    "    log_y = log_likelihood_fn(f, A, b, eta) + np.log(np.random.uniform())\n",
    "\n",
    "    theta = np.random.uniform(0, 2 * np.pi)\n",
    "    theta_min = theta - 2 * np.pi\n",
    "    theta_max = theta\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        f_prime = f * np.cos(theta) + nu * np.sin(theta)\n",
    "        ll = log_likelihood_fn(f_prime, A, b, eta)\n",
    "\n",
    "        if ll > log_y:\n",
    "            print(f\"θ: {theta:.2f}, log_y: {log_y:.2f}, log_ll: {ll:.2f}, min_constraint: {np.min(A @ f_prime + b):.4f}\")\n",
    "\n",
    "            violation = A @ f_prime + b\n",
    "            if np.all(violation >= 0):\n",
    "                return f_prime\n",
    "            elif np.min(violation) > -1e-6:\n",
    "                # Mild violation → likely due to approximation → project\n",
    "                try:\n",
    "                    projected = project_onto_constraints(A, b, f_prime)\n",
    "                    return projected\n",
    "                except RuntimeError:\n",
    "                    print(\"Projection failed\")\n",
    "                    continue\n",
    "\n",
    "            # Else: do not accept — continue slicing\n",
    "        # Not accepted: shrink bracket\n",
    "        if theta < 0:\n",
    "            theta_min = theta\n",
    "        else:\n",
    "            theta_max = theta\n",
    "        theta = np.random.uniform(theta_min, theta_max)\n",
    "\n",
    "    raise RuntimeError(\"ESS failed to find valid sample after max_attempts.\")\n",
    "\n",
    "def sample_tmvn_ess(mu, cov, A, b, X, y, n_samples, burn_in=100, eta_init=20.0, update_eta=False):\n",
    "    d = mu.shape[0]\n",
    "    zeta = mu.copy()\n",
    "    samples = []\n",
    "    eta = eta_init\n",
    "    count = 0\n",
    "\n",
    "    while len(samples) < n_samples:\n",
    "        zeta_centered = zeta - mu\n",
    "        zeta_centered = elliptical_slice_sampling(\n",
    "            f=zeta_centered,\n",
    "            cov=cov,\n",
    "            A=A,\n",
    "            b=b,\n",
    "            eta=eta,\n",
    "            log_likelihood_fn=lambda z, *_: log_likelihood_approx(z, A, b, eta)\n",
    "        )\n",
    "        zeta = zeta_centered + mu\n",
    "        if np.all(A @ zeta + b >= 0):\n",
    "            samples.append(zeta.copy())\n",
    "\n",
    "        if update_eta:\n",
    "            eta *= 1.01\n",
    "\n",
    "        if count > n_samples + 10:\n",
    "            raise ValueError(\"Max iterations reached\")\n",
    "        count += 1\n",
    "    samples = np.array(samples)\n",
    "    samples = samples[burn_in:]\n",
    "    return samples\n",
    "\n",
    "def sample_posterior(self, init, n_samples, eta=20, burn_in=1000, update_eta=True):\n",
    "    mu = init\n",
    "    cov = np.linalg.inv(self.cov_star_inverse)\n",
    "    A = self.constraints[\"M\"]\n",
    "    b = self.constraints[\"g\"]\n",
    "    X = self.Phi_matrix  # assume you store design matrix in self.X\n",
    "    y = self.y_train  # assume targets are in self.y\n",
    "\n",
    "    samples = sample_tmvn_ess(mu, cov, A, b, X, y, n_samples + burn_in, eta_init=eta, update_eta=update_eta)\n",
    "    return samples[burn_in:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "418ad007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from virtobs import VOGP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
